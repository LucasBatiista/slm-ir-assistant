{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9086ace",
   "metadata": {},
   "source": [
    "## Extração das Perguntas e Respostas do IRPF\n",
    "\n",
    "- Dados em data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-02-11 19:29:42,752 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:42,753 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:42,796 [RapidOCR] download_file.py:60: File exists and is valid: /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:42,797 [RapidOCR] main.py:50: Using /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,046 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,047 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,049 [RapidOCR] download_file.py:60: File exists and is valid: /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,050 [RapidOCR] main.py:50: Using /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,151 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,151 [RapidOCR] device_config.py:57: Using GPU device with ID: 0\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,228 [RapidOCR] download_file.py:60: File exists and is valid: /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-02-11 19:29:43,229 [RapidOCR] main.py:50: Using /home/lucas/Desktop/slm-ir-assistant/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = \"/home/lucas/Desktop/slm-ir-assistant/data/pdfs/perguntas_respostas_2022_IRPF.pdf\"\n",
    "converter = DocumentConverter()\n",
    "doc = converter.convert(source).document\n",
    "\n",
    "# print(doc.export_to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd1628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# text = doc.export_to_markdown()\n",
    "\n",
    "# re.findall(r'(?<!\\d)\\d{3}\\s+-', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be796c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Save that string to a file\n",
    "with open(\"perguntas_respostas_2023_IRPF.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8f62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALIDATION REPORT ---\n",
      "Total Extracted: 706\n",
      "✅ SUCCESS: Found exactly 706 unique questions.\n",
      "Saved extracted data to perguntas_respostas_2023_IRPF.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_and_validate_rfb_questions(text):\n",
    "    # 1. Regex Configuration\n",
    "    # Anchored to start of line, optional '##', negative lookbehind for digits\n",
    "    id_pattern = re.compile(r'^\\s*(?:##\\s*)?(?<!\\d)(\\d{3})\\s+-\\s*')\n",
    "    \n",
    "    # Matches lines starting with \"##\" (Topics/Metadata)\n",
    "    header_pattern = re.compile(r'^##\\s+(.*)')\n",
    "    \n",
    "    questions = []\n",
    "    current_topic = \"Geral\" # Default metadata\n",
    "    \n",
    "    # Buffers to hold multi-line text\n",
    "    current_lines = []\n",
    "    current_id = None\n",
    "    current_topic_snapshot = None\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        \n",
    "        # SKIP specific navigation lines if they appear strictly on their own\n",
    "        if \"Retorno ao sumário\" in line:\n",
    "            continue\n",
    "\n",
    "        # CHECK: Is this a Question? (Priority check)\n",
    "        id_match = id_pattern.match(line)\n",
    "        \n",
    "        if id_match:\n",
    "            # Save the PREVIOUS question found (if any)\n",
    "            if current_id:\n",
    "                questions.append(process_entry(current_id, current_topic_snapshot, current_lines))\n",
    "            \n",
    "            # Start a NEW question\n",
    "            current_id = id_match.group(1)\n",
    "            current_topic_snapshot = current_topic\n",
    "            current_lines = []\n",
    "            \n",
    "            # Remove the ID part from the line to get the question text started\n",
    "            content_start = id_match.end()\n",
    "            current_lines.append(line[content_start:].strip())\n",
    "            \n",
    "        # CHECK: Is this a Metadata Header? (Only if it's not a question)\n",
    "        elif header_pattern.match(line):\n",
    "            header_text = header_pattern.match(line).group(1).strip()\n",
    "            # Ignore headers that are likely sub-sections inside an answer\n",
    "            # We also ignore \"Retorno\" here just in case\n",
    "            ignore_keywords = [\"Atenção\", \"Dispensa\", \"Atividade rural\", \"Retorno\"]\n",
    "            if not any(keyword in header_text for keyword in ignore_keywords):\n",
    "                current_topic = header_text\n",
    "        \n",
    "        # OTHERWISE: It's part of the current Question/Answer text\n",
    "        else:\n",
    "            if current_id:\n",
    "                current_lines.append(line)\n",
    "\n",
    "    # Don't forget the very last question!\n",
    "    if current_id:\n",
    "        questions.append(process_entry(current_id, current_topic_snapshot, current_lines))\n",
    "\n",
    "    return questions\n",
    "\n",
    "def process_entry(q_id, topic, lines):\n",
    "    # Join lines with newline to preserve structure for regex (important for citations)\n",
    "    full_text = \"\\n\".join(lines)\n",
    "    \n",
    "    # 1. Split Question and Answer at the first '?'\n",
    "    if '?' in full_text:\n",
    "        parts = full_text.split('?', 1)\n",
    "        question_text = parts[0].strip() + \"?\"\n",
    "        answer_text = parts[1].strip()\n",
    "    else:\n",
    "        question_text = full_text\n",
    "        answer_text = \"\"\n",
    "\n",
    "    # 2. CLEAN FOOTERS (Consulte / Retorno)\n",
    "    # Remove these lines from the end to expose the legal citation\n",
    "    # Regex: Look for lines starting with \"Consulte\" or \"Retorno\" at the end of the text\n",
    "    # (?m) allows ^ to match the start of each line\n",
    "    answer_text = re.sub(r'(?m)^\\s*(Consulte|Retorno).*$', '', answer_text).strip()\n",
    "\n",
    "    # 3. EXTRACT LEGAL SOURCE (Robust Multi-line)\n",
    "    # Expanded keywords to catch all variations\n",
    "    legal_keywords = r\"(?:Lei|Decreto|Instrução|Regulamento|RIR|Ato|Solução|Parecer|Portaria|Constituição|Emenda|Medida)\"\n",
    "    \n",
    "    # Regex logic:\n",
    "    # \\(\\s*{kw}   -> Starts with ( followed by a keyword\n",
    "    # .*?         -> Match anything (non-greedy)\n",
    "    # \\)          -> Ends with )\n",
    "    # \\s*$        -> Must be at the very end of the string\n",
    "    legal_pattern = re.compile(\n",
    "        rf'\\(\\s*{legal_keywords}.*?\\)\\s*$', \n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    legal_source = None\n",
    "    match = legal_pattern.search(answer_text)\n",
    "    \n",
    "    if match:\n",
    "        legal_source = match.group(0).strip()\n",
    "        # Remove the legal source from the answer text\n",
    "        answer_text = answer_text[:match.start()].strip()\n",
    "        \n",
    "        # Post-cleanup: Sometimes removing the source leaves a trailing \".\" or whitespace\n",
    "        if answer_text.endswith('.'):\n",
    "            answer_text = answer_text[:-1].strip()\n",
    "\n",
    "    return {\n",
    "        \"id\": q_id,\n",
    "        \"metadata\": { \"section\": topic },\n",
    "        \"question\": question_text,\n",
    "        \"answer\": answer_text,\n",
    "        \"legal_source\": legal_source\n",
    "    }\n",
    "\n",
    "def validate_count(data):\n",
    "    # Extract all IDs found\n",
    "    found_ids = [int(item['id']) for item in data]\n",
    "    found_set = set(found_ids)\n",
    "    \n",
    "    expected_count = 706\n",
    "    missing = [i for i in range(1, expected_count + 1) if i not in found_set]\n",
    "    duplicates = [x for i, x in enumerate(found_ids) if found_ids.count(x) > 1]\n",
    "    \n",
    "    print(f\"--- VALIDATION REPORT ---\")\n",
    "    print(f\"Total Extracted: {len(found_ids)}\")\n",
    "    \n",
    "    if len(found_ids) == expected_count and not missing:\n",
    "        print(f\"✅ SUCCESS: Found exactly {expected_count} unique questions.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"❌ ERROR: Count mismatch.\")\n",
    "        if missing:\n",
    "            print(f\"   Missing IDs: {missing[:10]}... (Total {len(missing)})\")\n",
    "        if duplicates:\n",
    "            print(f\"   Duplicate IDs: {set(duplicates)}\")\n",
    "        return False\n",
    "\n",
    "# --- USAGE ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"perguntas_respostas_2023_IRPF.md\" # Make sure this matches your file name\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        data = extract_and_validate_rfb_questions(text)\n",
    "        \n",
    "        # Validate\n",
    "        if validate_count(data):\n",
    "            # Save to JSON if valid\n",
    "            output_file = \"perguntas_respostas_2023_IRPF.json\"\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Saved extracted data to {output_file}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file '{file_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
